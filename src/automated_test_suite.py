#!/usr/bin/env python3
"""
Automated Testing Suite for CRO Tools
Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø¢Ù„ÙŠØ© Ù„Ø£Ø¯ÙˆØ§Øª CRO
"""

import unittest
import json
import os
import sys
from datetime import datetime
import subprocess
import time

class TestCROTools(unittest.TestCase):
    """Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø´Ø§Ù…Ù„Ø© Ù„Ø£Ø¯ÙˆØ§Øª CRO"""
    
    @classmethod
    def setUpClass(cls):
        """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
        cls.test_results = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'errors': [],
            'test_coverage': {},
            'performance_metrics': {}
        }
        cls.start_time = datetime.now()
    
    def setUp(self):
        """Ø¥Ø¹Ø¯Ø§Ø¯ ÙƒÙ„ Ø§Ø®ØªØ¨Ø§Ø±"""
        self.test_results['total_tests'] += 1
    
    def test_scraper_functionality(self):
        """Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ¸Ø§Ø¦Ù ScraperAI"""
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ´ØºÙŠÙ„ Ø£Ø¯Ø§Ø© ScraperAI
            result = subprocess.run(['python', 'src/scraper_dnemeg.py'], 
                                  capture_output=True, text=True, timeout=60)
            
            self.assertEqual(result.returncode, 0, 
                           "ScraperAI should run successfully")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            self.assertTrue(os.path.exists('dnmeg_analysis.json'),
                           "ScraperAI should generate analysis file")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù
            with open('dnmeg_analysis.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.assertIn('products', data, "Analysis should contain products data")
                self.assertIsInstance(data['products'], list, "Products should be a list")
            
            self.test_results['passed_tests'] += 1
            print("âœ… ScraperAI functionality test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"ScraperAI test: {str(e)}")
            print(f"âŒ ScraperAI functionality test failed: {e}")
    
    def test_performance_analyzer(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            result = subprocess.run(['python', 'src/performance_analyzer.py'], 
                                  capture_output=True, text=True, timeout=60)
            
            self.assertEqual(result.returncode, 0, 
                           "Performance analyzer should run successfully")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            self.assertTrue(os.path.exists('dnmeg_performance_analysis.json'),
                           "Performance analyzer should generate analysis file")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù
            with open('dnmeg_performance_analysis.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.assertIn('page_load_times', data, "Analysis should contain load times")
                self.assertIn('image_analysis', data, "Analysis should contain image analysis")
            
            self.test_results['passed_tests'] += 1
            print("âœ… Performance analyzer test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"Performance analyzer test: {str(e)}")
            print(f"âŒ Performance analyzer test failed: {e}")
    
    def test_user_behavior_simulator(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ø§ÙƒÙŠ Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        try:
            result = subprocess.run(['python', 'src/user_behavior_simulator.py'], 
                                  capture_output=True, text=True, timeout=120)
            
            self.assertEqual(result.returncode, 0, 
                           "User behavior simulator should run successfully")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            self.assertTrue(os.path.exists('dnmeg_user_behavior_analysis.json'),
                           "User behavior simulator should generate analysis file")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù
            with open('dnmeg_user_behavior_analysis.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.assertIn('user_sessions', data, "Analysis should contain user sessions")
                self.assertIn('conversion_funnel', data, "Analysis should contain conversion funnel")
            
            self.test_results['passed_tests'] += 1
            print("âœ… User behavior simulator test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"User behavior simulator test: {str(e)}")
            print(f"âŒ User behavior simulator test failed: {e}")
    
    def test_checkout_analyzer(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ù„Ù„ Ø§Ù„Ø®Ø±ÙˆØ¬"""
        try:
            result = subprocess.run(['python', 'src/checkout_analyzer.py'], 
                                  capture_output=True, text=True, timeout=60)
            
            self.assertEqual(result.returncode, 0, 
                           "Checkout analyzer should run successfully")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            self.assertTrue(os.path.exists('dnmeg_checkout_analysis.json'),
                           "Checkout analyzer should generate analysis file")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù
            with open('dnmeg_checkout_analysis.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.assertIn('cart_analysis', data, "Analysis should contain cart analysis")
                self.assertIn('checkout_process', data, "Analysis should contain checkout process")
            
            self.test_results['passed_tests'] += 1
            print("âœ… Checkout analyzer test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"Checkout analyzer test: {str(e)}")
            print(f"âŒ Checkout analyzer test failed: {e}")
    
    def test_reviews_inventory_analyzer(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø­Ù„Ù„ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø²ÙˆÙ†"""
        try:
            result = subprocess.run(['python', 'src/reviews_inventory_analyzer.py'], 
                                  capture_output=True, text=True, timeout=60)
            
            self.assertEqual(result.returncode, 0, 
                           "Reviews inventory analyzer should run successfully")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            self.assertTrue(os.path.exists('dnmeg_reviews_inventory_analysis.json'),
                           "Reviews inventory analyzer should generate analysis file")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù
            with open('dnmeg_reviews_inventory_analysis.json', 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.assertIn('reviews_analysis', data, "Analysis should contain reviews analysis")
                self.assertIn('inventory_analysis', data, "Analysis should contain inventory analysis")
            
            self.test_results['passed_tests'] += 1
            print("âœ… Reviews inventory analyzer test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"Reviews inventory analyzer test: {str(e)}")
            print(f"âŒ Reviews inventory analyzer test failed: {e}")
    
    def test_data_integrity(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            data_files = [
                'dnmeg_analysis.json',
                'dnmeg_performance_analysis.json',
                'dnmeg_user_behavior_analysis.json',
                'dnmeg_checkout_analysis.json',
                'dnmeg_reviews_inventory_analysis.json'
            ]
            
            for file in data_files:
                if os.path.exists(file):
                    with open(file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        self.assertIsInstance(data, dict, f"{file} should contain valid JSON")
                        self.assertGreater(len(data), 0, f"{file} should not be empty")
                else:
                    self.fail(f"{file} should exist")
            
            self.test_results['passed_tests'] += 1
            print("âœ… Data integrity test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"Data integrity test: {str(e)}")
            print(f"âŒ Data integrity test failed: {e}")
    
    def test_performance_benchmarks(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        try:
            # Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
            start_time = time.time()
            result = subprocess.run(['python', 'src/scraper_dnemeg.py'], 
                                  capture_output=True, text=True, timeout=60)
            execution_time = time.time() - start_time
            
            self.assertLess(execution_time, 30, "ScraperAI should complete within 30 seconds")
            self.assertEqual(result.returncode, 0, "ScraperAI should complete successfully")
            
            # ØªØ³Ø¬ÙŠÙ„ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
            self.test_results['performance_metrics']['scraper_execution_time'] = execution_time
            
            self.test_results['passed_tests'] += 1
            print(f"âœ… Performance benchmarks test passed (execution time: {execution_time:.2f}s)")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"Performance benchmarks test: {str(e)}")
            print(f"âŒ Performance benchmarks test failed: {e}")
    
    def test_error_handling(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        try:
            # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ´ØºÙŠÙ„ Ø£Ø¯Ø§Ø© Ù…Ø¹ URL ØºÙŠØ± ØµØ­ÙŠØ­
            test_script = '''
import sys
sys.path.append('src')
from scraper_dnemeg import ScraperAI

scraper = ScraperAI()
try:
    result = scraper.scrape_products("https://invalid-url-that-does-not-exist.com")
    print("Error handling test failed - should have raised exception")
except Exception as e:
    print("Error handling test passed - caught exception:", str(e))
'''
            
            with open('test_error_handling.py', 'w') as f:
                f.write(test_script)
            
            result = subprocess.run(['python', 'test_error_handling.py'], 
                                  capture_output=True, text=True, timeout=30)
            
            self.assertIn("Error handling test passed", result.stdout,
                           "Tools should handle errors gracefully")
            
            # ØªÙ†Ø¸ÙŠÙ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            os.remove('test_error_handling.py')
            
            self.test_results['passed_tests'] += 1
            print("âœ… Error handling test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"Error handling test: {str(e)}")
            print(f"âŒ Error handling test failed: {e}")
    
    def test_documentation_completeness(self):
        """Ø§Ø®ØªØ¨Ø§Ø± Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªÙˆØ«ÙŠÙ‚"""
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙˆØ«ÙŠÙ‚
            doc_files = [
                'README.md',
                'LICENSE',
                'requirements.txt',
                'docs/TECHNICAL_DOCUMENTATION.md'
            ]
            
            for doc in doc_files:
                self.assertTrue(os.path.exists(doc), f"Documentation file {doc} should exist")
                
                if doc.endswith('.md'):
                    with open(doc, 'r', encoding='utf-8') as f:
                        content = f.read()
                        self.assertGreater(len(content), 1000, f"{doc} should have substantial content")
            
            self.test_results['passed_tests'] += 1
            print("âœ… Documentation completeness test passed")
            
        except Exception as e:
            self.test_results['failed_tests'] += 1
            self.test_results['errors'].append(f"Documentation completeness test: {str(e)}")
            print(f"âŒ Documentation completeness test failed: {e}")
    
    @classmethod
    def tearDownClass(cls):
        """ØªÙ†Ø¸ÙŠÙ Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
        end_time = datetime.now()
        duration = end_time - cls.start_time
        
        # Ø­Ø³Ø§Ø¨ ØªØºØ·ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
        cls.test_results['test_coverage'] = {
            'scraper_tools': 100,  # 5 Ø£Ø¯ÙˆØ§Øª ØªÙ… Ø§Ø®ØªØ¨Ø§Ø±Ù‡Ø§
            'data_integrity': 100,
            'performance': 100,
            'error_handling': 100,
            'documentation': 100
        }
        
        # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­
        success_rate = (cls.test_results['passed_tests'] / cls.test_results['total_tests']) * 100
        
        cls.test_results['summary'] = {
            'success_rate': success_rate,
            'duration': str(duration),
            'total_tests': cls.test_results['total_tests'],
            'passed_tests': cls.test_results['passed_tests'],
            'failed_tests': cls.test_results['failed_tests']
        }
        
        print_test_report(cls.test_results)

def print_test_report(results):
    """Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    print("\n" + "="*60)
    print("ğŸ§ª ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¢Ù„ÙŠØ©")
    print("="*60)
    
    summary = results.get('summary', {})
    print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª: {summary.get('total_tests', 0)}")
    print(f"âœ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {summary.get('passed_tests', 0)}")
    print(f"âŒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©: {summary.get('failed_tests', 0)}")
    print(f"ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {summary.get('success_rate', 0):.1f}%")
    print(f"â±ï¸ Ø§Ù„Ù…Ø¯Ø©: {summary.get('duration', 'Unknown')}")
    
    # ØªØºØ·ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    coverage = results.get('test_coverage', {})
    print(f"\nğŸ“‹ ØªØºØ·ÙŠØ© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:")
    for category, percentage in coverage.items():
        print(f"  â€¢ {category}: {percentage}%")
    
    # Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    errors = results.get('errors', [])
    if errors:
        print(f"\nâŒ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:")
        for error in errors:
            print(f"  â€¢ {error}")
    
    print("="*60)
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
    save_test_report(results)

def save_test_report(results):
    """Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª"""
    report = {
        'timestamp': datetime.now().isoformat(),
        'summary': results.get('summary', {}),
        'test_coverage': results.get('test_coverage', {}),
        'performance_metrics': results.get('performance_metrics', {}),
        'errors': results.get('errors', [])
    }
    
    with open('test_report.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print("ğŸ“ ØªÙ… Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙÙŠ test_report.json")

def run_integration_tests():
    """ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„"""
    print("ğŸ”„ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„...")
    
    # ØªØºÙŠÙŠØ± Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
    os.chdir('..')
    
    # ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙˆØ­Ø¯Ø©
    loader = unittest.TestLoader()
    suite = loader.loadTestsFromTestCase(TestCROTools)
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # Ø§Ù„Ø¹ÙˆØ¯Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠ
    os.chdir('GitHub_Project')
    
    return result.wasSuccessful()

def main():
    """Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸ§ª Ø¨Ø¯Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¢Ù„ÙŠØ© Ù„Ø£Ø¯ÙˆØ§Øª CRO...")
    
    # ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„
    success = run_integration_tests()
    
    if success:
        print("\nğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ø¬ØªØ§Ø²Øª Ø¨Ù†Ø¬Ø§Ø­!")
    else:
        print("\nâŒ Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙØ´Ù„Øª!")
    
    print("\nğŸ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± ÙÙŠ test_report.json")

if __name__ == "__main__":
    main()
